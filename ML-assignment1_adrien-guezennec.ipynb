{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Adrien Guezennec\n",
    "\n",
    "## Introduction\n",
    "The goal for this assignment was to implement from scratch a Naive Bayes, a cross validator and a ROC.\n",
    "I personnaly use Python as language.\n",
    "\n",
    "You can see my [repository](https://github.com/adrienGzc/machine-learning-lab) on Github you want.\n",
    "I added a Dockerfile if you don't want to run it in your environment.\n",
    "\n",
    "\n",
    "I structured my report the same order as I coded the assignment. So, Naive Bayes first after the Cross validator and to end the ROC.\n",
    "</br>\n",
    "\n",
    "## Naive Bayes\n",
    "To start my work I first take a look at [wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes) to check the implementation.\n",
    "Once I read it, I start design my class with the method public and private needed.\n",
    "I make it simpler so you just have the initialization of the Class and you can fit(), which mean train with the training data, and predict(), which mean predict the output class with the test data given in input.\n",
    "\n",
    "I'm gonna start to explain the fit() method and what she is doing inside, here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Training method. Take the training data and the target of the training data.\n",
    "  def fit(self, trainData=None, trainTarget=None):\n",
    "\n",
    "    # Store the data + label in the Naive Bayes class.\n",
    "    self.__setTrainData(trainData, trainTarget)\n",
    "\n",
    "    # Clean variables before to use it if algo used in cross validation or in a loop.\n",
    "    self.trainedFeature.clear()\n",
    "    self.splitedClasses.clear()\n",
    "\n",
    "    # Return a dictionnary with all the different label as a key with the instances related in it.\n",
    "    splitedCLasses = self.__classSpliter()\n",
    "\n",
    "    # For every class, we reduce all the instance into the number of instances, the mean and the standard deviation.\n",
    "    for key, value in splitedCLasses.items():\n",
    "      self.trainedFeature[key] = self.__squashFeature(value)\n",
    "    \n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to add comment to make it easier to read and to understand.\n",
    "Basically, this method take a training data with the label expected and store them in the class so I can have access eveywhere in my class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Store training data in the Naive Bayes class\n",
    "  def __setTrainData(self, trainData, targetData):\n",
    "    self.trainData = trainData\n",
    "    self.trainTarget = targetData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, I cluster all the instances into their own class label. This is going to help me after for the prediction class.\n",
    "Here is the code for the splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Divide data by class.\n",
    "  def __classSpliter(self):\n",
    "    for index, target in enumerate(self.trainData):\n",
    "      # Create new key in dict if class not already created.\n",
    "      if (self.trainTarget[index] not in self.splitedClasses):\n",
    "        self.splitedClasses[self.trainTarget[index]] = list()\n",
    "      # Add the instance to the corresponding class.\n",
    "      self.splitedClasses[self.trainTarget[index]].append(target)\n",
    "    return self.splitedClasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end it give me a dict() in python with the class label as a key and a list of all the instances attached.\n",
    "```javascript\n",
    "{1: [[6.3, 2.3, 4.4, 1.3],\n",
    "     [5.1, 2.5, 3.0, 1.1],\n",
    "     ...],\n",
    " 2: [[6.3, 2.9, 5.6, 1.8],\n",
    "     [6.8, 3.0, 5.5, 2.1],\n",
    "     ...]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is summarize the features of the instances. So, for each class I summarize the instances features to get the mean and the standard deviation for all features. Let me show you the code and explain you what I did in the squashFeature method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Calcule mean and standard deviation for each column (feature) in the training data.\n",
    "  def __squashFeature(self, classData):\n",
    "    tmp = list()\n",
    "\n",
    "    # The built-in zip give me all data from 1 column (feature), at once, on the classData list.\n",
    "    for feature in zip(*classData):\n",
    "      tmp.append((len(feature), self.__mean(feature), self.__standardDeviation(feature)))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take profit of the zip built-in to get each feature of all instances at the same time and make my operation on it. So, I can easily get the mean of all input from feature 1 and the standard deviation at the same time. And this for all features.\n",
    "For the mean and the standard deviation I thought using the numpy library but I didn't know if we could use external library for those kind of calculus. So, I implemented the function myself using this [website](https://www.w3schools.com/python/python_ml_standard_deviation.asp) (for the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Return the mean of a list.\n",
    "  def __mean(self, feature):\n",
    "    return sum(feature) / len(feature)\n",
    "\n",
    "\n",
    "  # Return the variance of a list.\n",
    "  def __variance(self, feature):\n",
    "    meanDifference = list()\n",
    "    mean = self.__mean(feature)\n",
    "\n",
    "    for instance in feature:\n",
    "      meanDifference.append(pow((instance - mean), 2))\n",
    "    return self.__mean(meanDifference)\n",
    "\n",
    "\n",
    "  # Return the standard deviation from a list.\n",
    "  def __standardDeviation(self, feature):\n",
    "    return round(math.sqrt(self.__variance(feature)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing crazy here, the w3school website explain it very well to reproduce it.\n",
    "</br>\n",
    "\n",
    "After training, place to prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Method to predict, should be used after the fit method.\n",
    "  def predict(self, testData):\n",
    " \n",
    "    # If there is no training done before then return false with error message.\n",
    "    if len(self.trainedFeature) is 0:\n",
    "      print('Error: no training data recorded. Please fit (train) before to predict.')\n",
    "      return False\n",
    "\n",
    "    self.__setTestData(testData)\n",
    "\n",
    "    # For every test instance we predict the class which she is the closer.\n",
    "    predictions = list()\n",
    "    for testInstance in self.testData:\n",
    "      predictions.append(self.__getPredictionForInstance(testInstance))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part of the prediction is the for loop at the end. For each instance test I make a prediction to get the class predicted and the class probabilities output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Return, for the instances, the predicted class + the probabilities in a tuple.\n",
    "  def __getPredictionForInstance(self, testInstance):\n",
    "    classValue = None\n",
    "    predictedClass = None\n",
    "    # Get the class probability for the test instance.\n",
    "    probaResults = self.__getPropabilities(testInstance)\n",
    "\n",
    "    # Check which class as the most probability, this is gonna be out prediction.\n",
    "    for key, value in probaResults.items():\n",
    "      # If first loop lap OR the probability is higher than the actual then set the new class as the highest proba.\n",
    "      if (classValue is None or classValue < value):\n",
    "        classValue = value\n",
    "        predictedClass = key\n",
    "    return ((predictedClass, probaResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Return the classes probability based on the instance given.\n",
    "  def __getPropabilities(self, testInstance):\n",
    "    probabilities = dict()\n",
    "\n",
    "    for key, value in self.trainedFeature.items():\n",
    "      probabilities[key] = value[0][0] / len(self.trainData)\n",
    "\n",
    "      for index in range(len(value)):\n",
    "        # Get the mean and standard deviation from each feature\n",
    "        _nbInstance, mean, standardDeviation = value[index]\n",
    "        # Multiply the gaussian for each feature \n",
    "        probabilities[key] *= self.__gaussian(testInstance[index], mean, standardDeviation)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Awful to read, I apologize for that, but correspond to the gaussian normal distribution.\n",
    "  def __gaussian(self, feature, mean, standardDeviation):\n",
    "    return (1 / (math.sqrt(2 * math.pi) * standardDeviation)) * math.exp(-((feature - mean) ** 2 / (2 * standardDeviation ** 2 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see I put the 3 functions I used for the prediction. They are all related so it's gonna be easier to explain if you have a good picture of what happen.\n",
    "So here, even if you can understand with the comment, I summarize the features of the test instance with each feature of each class trained. For that, I used the gaussian normal distribution from the Naive Bayes wiki page. At the end I got a probability for each class that I can compare and choose the highest one. An evolution here would be to adapt the choosing process of when a probability is negatif or positif.\n",
    "\n",
    "\n",
    "## Cross validator\n",
    "For the cross validator I only make one public method which is score(). At the initialization you indicate the algorithm, a dataset and the number of fold that you want. The subject asked for 10 fold so every test was made on a base off 10 folds but I tried other number and work as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Calculate the score of the accuracy:\n",
    "  #   - all the accuracy as a list, len(list accuracy) = nbFolds.\n",
    "  #   - the mean accuracy based on all the accuracy.\n",
    "  #   - a list with -> Prediction, Classes probabilities, Real target expected.\n",
    "  def score(self):\n",
    "    if (self.__checkNotEmptyAttributes() is False):\n",
    "      return False\n",
    "\n",
    "    # Split the data into K folds.\n",
    "    self.__splitDatasetIntoKFolds()\n",
    "    accuracyScores = list()\n",
    "    for index, fold in enumerate(self.folds):\n",
    "      trainData = self.__getTrainData(self.folds, index)\n",
    "      # Extract the label from the dataset.\n",
    "      targetTrain = self.__getTargetFromData(trainData)\n",
    "      testData = copy.deepcopy(fold)\n",
    "      targetTest = self.__getTargetFromData(testData)\n",
    "\n",
    "      # Train the Naive Bayes algorithm.\n",
    "      self.algorithm.fit(trainData, targetTrain, False)\n",
    "      # Predict with the fold.\n",
    "      predictionFold = self.algorithm.predict(testData)\n",
    "      # Add to the data for the ROC the prediction information with the target label.\n",
    "      self.rocData.extend(self.__appendTargetToPrediction(targetTest, predictionFold))\n",
    "      # Add the accuracy calculate.\n",
    "      accuracyScores.append(self.__getAccuracy(targetTest, predictionFold))\n",
    "    return accuracyScores, sum(accuracyScores) / len(accuracyScores), self.rocData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope the variable name and the comment help you to understand what the function are and used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # nbInstances as to be lower than nbFolds, I round the return to get a integer and not a float.\n",
    "  def __getFoldSize(self, nbInstances, nbFolds):\n",
    "    return round(nbInstances / nbFolds)\n",
    "\n",
    "  # Fill the folds Class variable with all folds of instances shuffled.\n",
    "  def __splitDatasetIntoKFolds(self):\n",
    "    copyDataset = self.dataset.copy()\n",
    "    # Desorganize the dataset\n",
    "    random.shuffle(copyDataset)\n",
    "    # Get the number of instances in each fold.\n",
    "    foldSize = self.__getFoldSize(len(self.dataset), self.nbFolds)\n",
    "\n",
    "    # I move the pointer start and end to cur the dataset into the number of instances calculated.\n",
    "    for nb in range(self.nbFolds):\n",
    "      start = foldSize * nb\n",
    "      end = foldSize + start\n",
    "      self.folds.append(copyDataset[start:end])\n",
    "\n",
    "  # Extract the label (target) from a dataset, it must be the last column.\n",
    "  def __getTargetFromData(self, dataset):\n",
    "    return [instance.pop(-1) for instance in dataset]\n",
    "\n",
    "  # Count the correct answer and return the accuracy of them, scaled on 0 to 100%.\n",
    "  def __getAccuracy(self, original, predictions):\n",
    "    nbCorrectPredictions = 0\n",
    "\n",
    "    # Loop through all the predictions.\n",
    "    for index in range(len(predictions)):\n",
    "      # Get the class predicted.\n",
    "      predictClass = predictions[index][0]\n",
    "\n",
    "      # If she correspond to the target label then add a correct answer.\n",
    "      if (original[index] == predictClass):\n",
    "        nbCorrectPredictions += 1\n",
    "\n",
    "    return nbCorrectPredictions / len(original) * 100\n",
    "\n",
    "  # Return a simple list of instances as a deep copy and delete the testing fold.\n",
    "  def __getTrainData(self, dataToSquash, indexToRemove):\n",
    "    data = copy.deepcopy(self.folds)\n",
    "    data.pop(indexToRemove)\n",
    "    return sum(data, [])\n",
    "\n",
    "  # Some magic here. Add the target label to the prediction information for the ROC.\n",
    "  def __appendTargetToPrediction(self, targets, predictions):\n",
    "    for index in range(len(predictions)):\n",
    "      tmp = list(predictions[index])\n",
    "      tmp.append(targets[index])\n",
    "      predictions[index] = tmp\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the split I round the result to get a integer and not a float. I used it to get the number of instance in each fold and so I can start the spliting on the list of instances.\n",
    "The problem I got here was the copy of the folds. Basically, I had to make a deep copy and not a shallow copy because a shallow copy doesn't change the address too deep so I had side effect from the copy to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "  def __init__(self, algo=None, dataset=None, nbFolds=10):\n",
    "    random.seed(1)\n",
    "    self.folds = list()\n",
    "    self.algorithm = algo\n",
    "    self.dataset = list(dataset)\n",
    "    self.nbFolds = nbFolds\n",
    "    self.rocData = list()\n",
    "\n",
    "  # Method to check if the CrossValidator class as everything needed to start.\n",
    "  def __checkNotEmptyAttributes(self):\n",
    "    if (self.algorithm is None or self.dataset is None or self.nbFolds <= 1):\n",
    "      print(\"Error: Algorithm and dataset shouldn't be empty and nbFolds neither less nor equal to 0\")\n",
    "      return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a verificationnn function to see if I can start the cross validation or not.\n",
    "\n",
    "## ROC\n",
    "For the plot I used the matplot lib to display the ROC Curve.\n",
    "I based my ROC on the [wikipedia page](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and this [blog](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/) I found on internet which explain it very well.\n",
    "Even though, I struggle to get a real result on the curve..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ROC:\n",
    "  def __init__(self):\n",
    "    self.tpr = list()\n",
    "    self.fpr = list()\n",
    "\n",
    "  # Calculate the ROC with the information from the prediction given by the cross validator.\n",
    "  def rocCurve(self, rocData):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for index in range(len(rocData)):\n",
    "      # Get the negative class.\n",
    "      class0 = min(rocData[index][1])\n",
    "      # Get the positive class.\n",
    "      class1 = max(rocData[index][1])\n",
    "      # Get the predicted class by the Naive Bayes.\n",
    "      predictClass = rocData[index][0]\n",
    "      # Get the target label expected.\n",
    "      target = rocData[index][2]\n",
    "\n",
    "      # Main if forest to fill the appropriate variable for the TPR and the FPR.\n",
    "      if (predictClass == class1 and target == predictClass):\n",
    "        tp += 1\n",
    "      elif (predictClass == class1 and target is not predictClass):\n",
    "        fp += 1\n",
    "      elif (predictClass == class0 and target == predictClass):\n",
    "        tn += 1\n",
    "      elif (predictClass == class0 and target is not predictClass):\n",
    "        fn += 1\n",
    "      # Based on wiki, calculate the TRP with the previous variable.\n",
    "      self.tpr.append(tp / (tp + fn))\n",
    "      # Same as TPR but for FPR.\n",
    "      self.fpr.append(fp / (fn + tp))\n",
    "    self.tpr.sort()\n",
    "    self.tpr.insert(0, 0.0)\n",
    "    self.tpr.insert(len(self.tpr), 1.0)\n",
    "    self.fpr.sort()\n",
    "    self.fpr.insert(0, 0.0)\n",
    "    self.fpr.insert(len(self.fpr), 1.0)\n",
    "\n",
    "  # Display the ROC Curve with matplot.    \n",
    "  def showROC(self):\n",
    "    lw = 1.5\n",
    "    plt.plot(self.fpr, self.tpr, color='darkorange', lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.02, 1.02])\n",
    "    plt.ylim([-0.02, 1.02])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first problem was that I didn't sort the value of the TPR and FPR, so the curve was messy and didn't had any sense. After that I insert a 0.0 value and a 1.0 value to link the curve to the start and end point but this is still not the right ROC curve.\n",
    "\n",
    "\n",
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-232b6aa4f283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mmainWhitoutFirstFlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mmainWhitoutMiddleFlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mmainWhitoutLastFlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-232b6aa4f283>\u001b[0m in \u001b[0;36mmainWhitoutFirstFlower\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mroc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrocCurve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrocData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0mroc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowROC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SWEDEN/MACHINE-LEARNING/LABS/machine-learning-lab/ROC.py\u001b[0m in \u001b[0;36mrocCurve\u001b[0;34m(self, rocData)\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0mfn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;31m# Based on wiki, calculate the TRP with the previous variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0;31m# Same as TPR but for FPR.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pprint\n",
    "from sklearn import datasets\n",
    "\n",
    "import ROC\n",
    "import NaiveBayes\n",
    "import CrossValidator\n",
    "\n",
    "# Add the target label at the end of the dataset. Needed to shuffle the data easily.\n",
    "def concateTargetWithDataset(dataset, targetDataset):\n",
    "  data = list()\n",
    "  for index, instance in enumerate(dataset):\n",
    "    tmp = list(instance)\n",
    "    tmp.append(targetDataset[index])\n",
    "    data.append(tmp)\n",
    "  return data\n",
    "\n",
    "# Just the same but whitout a different flower (3) to stay on a binary classification.\n",
    "def mainWhitoutFirstFlower():\n",
    "  irisData = datasets.load_iris()\n",
    "  irisData.data = irisData.data[:-50]\n",
    "  irisData.target = irisData.target[:-50]\n",
    "  newDataset = concateTargetWithDataset(irisData.data, irisData.target)\n",
    "\n",
    "  naiveBayes = NaiveBayes.NaiveBayes()\n",
    "  crossValidator = CrossValidator.CrossValidator(algo=naiveBayes, dataset=newDataset, nbFolds=10)\n",
    "  _scoresByFold, meanAccuracy, rocData = crossValidator.score()\n",
    "  print('Accuracy: %.2f%%' % meanAccuracy)\n",
    "\n",
    "  roc = ROC.ROC()\n",
    "  roc.rocCurve(rocData)\n",
    "  roc.showROC()\n",
    "\n",
    "# Just the same but whitout a different flower (2) to stay on a binary classification.\n",
    "def mainWhitoutMiddleFlower():\n",
    "  irisData = datasets.load_iris()\n",
    "  irisData.data = [instance for index, instance in enumerate(irisData.data) if index < 51 or index > 100]\n",
    "  irisData.target = list(filter(lambda label: label != 1, irisData.target))\n",
    "  newDataset = concateTargetWithDataset(irisData.data, irisData.target)\n",
    "\n",
    "  naiveBayes = NaiveBayes.NaiveBayes()\n",
    "  crossValidator = CrossValidator.CrossValidator(algo=naiveBayes, dataset=newDataset, nbFolds=10)\n",
    "  _scoresByFold, meanAccuracy, rocData = crossValidator.score()\n",
    "  print('Accuracy: %.2f%%' % meanAccuracy)\n",
    "\n",
    "  roc = ROC.ROC()\n",
    "  roc.rocCurve(rocData)\n",
    "  roc.showROC()\n",
    "\n",
    "# Whitout the last flower (1) to stay on a binary classification.\n",
    "def mainWhitoutLastFlower():\n",
    "  irisData = datasets.load_iris()\n",
    "  irisData.data = irisData.data[50:]\n",
    "  irisData.target = irisData.target[50:]\n",
    "  newDataset = concateTargetWithDataset(irisData.data, irisData.target)\n",
    "\n",
    "  naiveBayes = NaiveBayes.NaiveBayes()\n",
    "  crossValidator = CrossValidator.CrossValidator(algo=naiveBayes, dataset=newDataset, nbFolds=10)\n",
    "  _scoresByFold, meanAccuracy, rocData = crossValidator.score()\n",
    "  print('Accuracy: %.2f%%' % meanAccuracy)\n",
    "\n",
    "  roc = ROC.ROC()\n",
    "  roc.rocCurve(rocData)\n",
    "  roc.showROC()\n",
    "\n",
    "# Try with all flower, expect with the ROC as the ROC is for binary classification\n",
    "def mainWIthAllFlower():\n",
    "  irisData = datasets.load_iris()\n",
    "  newDataset = concateTargetWithDataset(irisData.data, irisData.target)\n",
    "\n",
    "  naiveBayes = NaiveBayes.NaiveBayes()\n",
    "  crossValidator = CrossValidator.CrossValidator(algo=naiveBayes, dataset=newDataset, nbFolds=10)\n",
    "  _scoresByFold, meanAccuracy, _rocData = crossValidator.score()\n",
    "  print('Accuracy: %.2f%%' % meanAccuracy)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mainWhitoutFirstFlower()\n",
    "    mainWhitoutMiddleFlower()\n",
    "    mainWhitoutLastFlower()\n",
    "    mainWIthAllFlower()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
